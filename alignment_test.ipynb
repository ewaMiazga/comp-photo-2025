{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rawpy\n",
    "\n",
    "\n",
    "def pack_raw(raw, white_level):\n",
    "    \"\"\"Packs Bayer image to 4 channels\"\"\"\n",
    "    img = raw.raw_image_visible\n",
    "\n",
    "\n",
    "    img = np.expand_dims(img, axis=2)\n",
    "\n",
    "    out = np.concatenate((img[0::2, 0::2],\n",
    "                          img[0::2, 1::2],\n",
    "                          img[1::2, 1::2],\n",
    "                          img[1::2, 0::2]), axis=2, dtype=np.float32)\n",
    "    black_level = np.array(raw.black_level_per_channel, dtype=np.float32)[None, None, :]\n",
    "    \n",
    "    print(out.max(), out.min(), white_level, black_level)\n",
    "    out = (out - black_level) / (float(white_level) - black_level)\n",
    "    print(out.max(), out.min())\n",
    "\n",
    "\n",
    "    out = (out * 255.0).astype(np.int8)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "def align_images_single_channel(img1, img2):\n",
    "    \"\"\"Aligns img2 to img1 using ORB feature matching and RANSAC.\"\"\"\n",
    "    orb = cv2.ORB_create(nfeatures=5000)\n",
    "\n",
    "    # Detect keypoints and descriptors\n",
    "    kp1, des1 = orb.detectAndCompute(img1, mask=None)\n",
    "    kp2, des2 = orb.detectAndCompute(img2, mask=None)\n",
    "\n",
    "    # Match features using BFMatcher\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    matches = bf.match(des1, des2)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "    # Use RANSAC to find homography\n",
    "    if len(matches) > 10:\n",
    "        src_pts = np.float32([kp2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "        dst_pts = np.float32([kp1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "        \n",
    "        H, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, ransacReprojThreshold=5.0)\n",
    "        \n",
    "        # Warp img2 to align with img1 (preserving colors)\n",
    "        aligned_img = cv2.warpPerspective(img2, H, (img1.shape[1], img1.shape[0]))\n",
    "        \n",
    "        return aligned_img, H\n",
    "    else:\n",
    "        raise ValueError(\"Not enough matches found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16088.0 1060.0 14605 [[[1024. 1024. 1024. 1025.]]]\n",
      "1.1091967 0.0026507622\n",
      "16088.0 1016.0 14605 [[[1024. 1024. 1024. 1024.]]]\n",
      "1.1091967 -0.00058905827\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([15319, 15319, 15319, 15319], 14605)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_image_raw = rawpy.imread('first-dataset/first-dataset-RAW/IMG_7781.CR2')\n",
    "diffused_image_raw = rawpy.imread('first-dataset/first-dataset-RAW/IMG_7782.CR2')\n",
    "\n",
    "packed_original = pack_raw(original_image_raw, original_image_raw.white_level)\n",
    "packed_diffused = pack_raw(diffused_image_raw, original_image_raw.white_level)\n",
    "\n",
    "\n",
    "\n",
    "#print(packed_original.max(), packed_original.min())\n",
    "#align_images_single_channel(\n",
    "#   packed_original[:, :, 0][:, :, None],\n",
    "#   packed_diffused\n",
    "#   #np.repeat(packed_original[:, :, 0][:, :, None], repeats=3, axis=2),\n",
    "#    #np.repeat(packed_diffused[:, :, 0][:, :, None], repeats=3, axis=2),\n",
    "#)\n",
    "original_image_raw.camera_white_level_per_channel, original_image_raw.white_level\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 5,  5,  5],\n",
       "        [ 5,  5,  5],\n",
       "        [ 5,  5,  5],\n",
       "        ...,\n",
       "        [46, 46, 46],\n",
       "        [46, 46, 46],\n",
       "        [47, 47, 47]],\n",
       "\n",
       "       [[ 5,  5,  5],\n",
       "        [ 5,  5,  5],\n",
       "        [ 5,  5,  5],\n",
       "        ...,\n",
       "        [47, 47, 47],\n",
       "        [48, 48, 48],\n",
       "        [48, 48, 48]],\n",
       "\n",
       "       [[ 5,  5,  5],\n",
       "        [ 5,  5,  5],\n",
       "        [ 6,  6,  6],\n",
       "        ...,\n",
       "        [47, 47, 47],\n",
       "        [46, 46, 46],\n",
       "        [48, 48, 48]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[13, 13, 13],\n",
       "        [15, 15, 15],\n",
       "        [13, 13, 13],\n",
       "        ...,\n",
       "        [61, 61, 61],\n",
       "        [60, 60, 60],\n",
       "        [63, 63, 63]],\n",
       "\n",
       "       [[13, 13, 13],\n",
       "        [11, 11, 11],\n",
       "        [10, 10, 10],\n",
       "        ...,\n",
       "        [63, 63, 63],\n",
       "        [63, 63, 63],\n",
       "        [59, 59, 59]],\n",
       "\n",
       "       [[ 7,  7,  7],\n",
       "        [ 7,  7,  7],\n",
       "        [ 7,  7,  7],\n",
       "        ...,\n",
       "        [59, 59, 59],\n",
       "        [61, 61, 61],\n",
       "        [60, 60, 60]]], dtype=int8)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.repeat(packed_original[:, :, 0][:, :, None], repeats=3, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def align_images_raw(path1, path2):\n",
    "    raw1 = rawpy.imread(path1)\n",
    "    raw2 = rawpy.imread(path2)\n",
    "\n",
    "    packed1 = pack_raw(raw1, raw1.white_level)    \n",
    "\n",
    "    packed1R, packed1G1, packed1B, packed1G2 = packed1[:,:,0], packed1[:,:,1], packed1[:,:,2], packed1[:,:,3]\n",
    "    \n",
    "    packed2 = pack_raw(raw2, raw1.white_level)\n",
    "\n",
    "    packed2R, packed2G1, packed2B, packed2G2 = packed2[:,:,0], packed2[:,:,1], packed2[:,:,2], packed2[:,:,3]\n",
    "\n",
    "    pairs = [(packed1R, packed2R), (packed1G1, packed2G1), (packed1B, packed2B), (packed1G2, packed2G2)]\n",
    "    aligned_images = []\n",
    "    projection_matrices = []\n",
    "    \n",
    "    # Calculate projections for each color channel individually\n",
    "    for img1, img2 in pairs:\n",
    "        aligned, projection_matrix = align_images_single_channel(img1[:,:,None], img2[:,:,None])\n",
    "        aligned = aligned\n",
    "        aligned_images.append(aligned)\n",
    "        projection_matrices.append(projection_matrix)\n",
    "\n",
    "    # TODO: check projection matrices\n",
    "\n",
    "    H = 2 * packed1.shape[0]\n",
    "    W = 2 * packed1.shape[1]\n",
    "\n",
    "    \n",
    "    raw = rawpy.imread(path1)\n",
    "    raw.raw_image_visible[0:H:2, 0:W:2] = aligned_images[0]\n",
    "    raw.raw_image_visible[0:H:2, 1:W:2] = aligned_images[1]\n",
    "    raw.raw_image_visible[1:H:2, 1:W:2] = aligned_images[2]\n",
    "    raw.raw_image_visible[1:H:2, 0:W:2] = aligned_images[3]\n",
    "    #TODO: crop original image\n",
    "\n",
    "    #TODO: intensity alignemnt\n",
    "\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) /Users/xperience/GHA-OpenCV-Python2/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.simd_helpers.hpp:92: error: (-2:Unspecified error) in function 'cv::impl::(anonymous namespace)::CvtHelper<cv::impl::(anonymous namespace)::Set<3, 4, -1>, cv::impl::(anonymous namespace)::Set<1, -1, -1>, cv::impl::(anonymous namespace)::Set<0, 2, 5>, cv::impl::(anonymous namespace)::NONE>::CvtHelper(cv::InputArray, cv::OutputArray, int) [VScn = cv::impl::(anonymous namespace)::Set<3, 4, -1>, VDcn = cv::impl::(anonymous namespace)::Set<1, -1, -1>, VDepth = cv::impl::(anonymous namespace)::Set<0, 2, 5>, sizePolicy = cv::impl::(anonymous namespace)::NONE]'\n> Invalid number of channels in input image:\n>     'VScn::contains(scn)'\n> where\n>     'scn' is 1\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m align_images_raw(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst-dataset/first-dataset-RAW/IMG_7781.CR2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst-dataset/first-dataset-RAW/IMG_7782.CR2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[22], line 19\u001b[0m, in \u001b[0;36malign_images_raw\u001b[0;34m(path1, path2)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Calculate projections for each color channel individually\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img1, img2 \u001b[38;5;129;01min\u001b[39;00m pairs:\n\u001b[0;32m---> 19\u001b[0m     aligned, projection_matrix \u001b[38;5;241m=\u001b[39m align_images_single_channel(img1[:,:,\u001b[38;5;28;01mNone\u001b[39;00m], img2[:,:,\u001b[38;5;28;01mNone\u001b[39;00m])\n\u001b[1;32m     20\u001b[0m     aligned \u001b[38;5;241m=\u001b[39m aligned\n\u001b[1;32m     21\u001b[0m     aligned_images\u001b[38;5;241m.\u001b[39mappend(aligned)\n",
      "Cell \u001b[0;32mIn[10], line 9\u001b[0m, in \u001b[0;36malign_images_single_channel\u001b[0;34m(img1, img2)\u001b[0m\n\u001b[1;32m      6\u001b[0m orb \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mORB_create(nfeatures\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Detect keypoints and descriptors\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m kp1, des1 \u001b[38;5;241m=\u001b[39m orb\u001b[38;5;241m.\u001b[39mdetectAndCompute(img1, mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     10\u001b[0m kp2, des2 \u001b[38;5;241m=\u001b[39m orb\u001b[38;5;241m.\u001b[39mdetectAndCompute(img2, mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Match features using BFMatcher\u001b[39;00m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.9.0) /Users/xperience/GHA-OpenCV-Python2/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.simd_helpers.hpp:92: error: (-2:Unspecified error) in function 'cv::impl::(anonymous namespace)::CvtHelper<cv::impl::(anonymous namespace)::Set<3, 4, -1>, cv::impl::(anonymous namespace)::Set<1, -1, -1>, cv::impl::(anonymous namespace)::Set<0, 2, 5>, cv::impl::(anonymous namespace)::NONE>::CvtHelper(cv::InputArray, cv::OutputArray, int) [VScn = cv::impl::(anonymous namespace)::Set<3, 4, -1>, VDcn = cv::impl::(anonymous namespace)::Set<1, -1, -1>, VDepth = cv::impl::(anonymous namespace)::Set<0, 2, 5>, sizePolicy = cv::impl::(anonymous namespace)::NONE]'\n> Invalid number of channels in input image:\n>     'VScn::contains(scn)'\n> where\n>     'scn' is 1\n"
     ]
    }
   ],
   "source": [
    "align_images_raw('first-dataset/first-dataset-RAW/IMG_7781.CR2', 'first-dataset/first-dataset-RAW/IMG_7782.CR2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
